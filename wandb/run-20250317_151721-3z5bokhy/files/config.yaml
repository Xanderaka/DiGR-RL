_wandb:
    value:
        cli_version: 0.19.8
        m: []
        python_version: 3.12.3
        t:
            "1":
                - 1
                - 5
                - 53
                - 55
            "2":
                - 1
                - 5
                - 53
                - 55
            "3":
                - 15
                - 16
                - 23
                - 55
                - 61
            "4": 3.12.3
            "5": 0.19.8
            "8":
                - 3
                - 5
            "12": 0.19.8
            "13": windows-amd64
data:
    value:
        amp_pipeline: <src.signal_processing.pipeline.Pipeline object at 0x000001710E4D0740>
        bvp_agg: sum
        bvp_pipeline: 1
        data_dir: data
        dataset_type: single_user_small
        downsample_multiplier: 2
        phase_pipeline: <src.signal_processing.pipeline.Pipeline object at 0x000001710E4D1B20>
        transformation: null
debug:
    value:
        is_debug: false
        offline: false
        on_cpu: false
embed:
    value:
        actor_dropout: 0.4
        actor_num_layers: 4
        agent_type: known
        anneal_lr: true
        clip_coef: 0.2
        clip_value_loss: true
        critic_dropout: 0.5
        critic_num_layers: 4
        embed_size: 33
        entropy_coef: 0
        epochs: 4
        gae_lambda: 0.8630898726372189
        gamma: 0.9573217957464132
        lr: 0.0025678916361578877
        max_grad_norm: 0.5
        norm_advantage: true
        reward_function: contrastive
        start_epoch: 35
        target_kl: null
        value_func_coef: 0.5
        value_type: probability-measure
encoder:
    value:
        activation_fn: leaky
        dropout: 0.1758769924448918
        initial_kernel_size: 8
        latent_dim: 60
        num_conv_layers: 4
mt:
    value:
        decoder_activation_fn: leaky
        decoder_dropout: 0.25625995103954213
        predictor_activation_fn: selu
        predictor_dropout: 0.28004446618639806
        predictor_num_layers: 6
optim_loss:
    value:
        alpha: 0
        beta: 0.5
        lr: 5e-05
        optimizer: adam
train:
    value:
        batch_size: 32
        checkpoint_dir: checkpoints
        epochs: 5
        ui: tqdm
