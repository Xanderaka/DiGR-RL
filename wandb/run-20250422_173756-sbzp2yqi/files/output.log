Running training on CPU
Loading dataset train
Found pregenerated data dir. Using pregenerated data.
Loading complete. Took 0.00 s.
Loading dataset validation
Found pregenerated data dir. Using pregenerated data.
Loading complete. Took 0.00 s.
Building models...
Completed model building. Took 0.09 s.
Epoch: 1 of 50 | Training loss: -.--:   0%|                                                                                          | 0/12000 [00:00<?, ?it/s]
Preparation complete. Starting training...
Training model...
torch.Size([16, 153])
tensor([[ 2.0990e-01, -3.3879e-02, -6.4799e-02, -6.1985e-02,  5.5862e-03,
          2.1340e-01, -2.5668e-01,  1.8531e-01, -1.1260e-01, -6.0207e-01,
          4.9271e-01, -1.6056e-01, -4.3884e-01,  1.2830e-01, -3.3190e-02,
          4.9547e-02, -3.5058e-01,  2.8530e-02,  1.6637e-01,  1.4614e-01],
        [ 3.6557e-01,  1.0098e-01,  1.0882e-01, -9.6532e-02, -2.4288e-01,
          4.9156e-01, -3.1060e-01,  9.9614e-02, -3.6368e-01, -6.4283e-01,
          5.0839e-01, -1.1007e-01, -2.8258e-01,  6.6538e-02, -1.0432e-01,
          1.7272e-01, -1.2155e-01,  3.7237e-03, -1.3251e-01, -6.7886e-02],
        [ 5.9002e-02, -7.9041e-02, -2.4129e-01,  9.2613e-02, -1.8030e-01,
          2.4119e-01, -6.4433e-02,  1.9077e-01, -2.9598e-01, -5.6916e-01,
          5.4757e-01, -1.3632e-01, -3.4303e-01,  1.3682e-01, -1.8266e-01,
          1.6298e-01, -8.2856e-02,  2.8035e-02, -1.7753e-02,  2.1127e-01],
        [ 1.3210e-01, -1.6834e-01, -6.1097e-02,  3.9104e-01, -6.0561e-02,
          2.2283e-02, -1.2869e-01,  1.8365e-01, -3.5718e-01, -5.8298e-01,
          4.9747e-01, -1.9892e-01, -3.2894e-01,  9.0050e-02,  4.0893e-02,
          1.0018e-01, -7.5670e-02, -1.4540e-01, -5.4403e-03,  1.7440e-01],
        [ 1.2500e-01, -2.2859e-01, -8.3060e-02,  2.2443e-01, -1.0910e-01,
          1.8913e-01, -2.7952e-01,  1.5200e-01, -3.6451e-01, -6.2561e-01,
          6.2532e-01,  6.5566e-02, -4.0404e-01,  1.9474e-01, -2.2724e-02,
          1.1512e-02, -2.0920e-02, -2.5728e-01, -9.8317e-02,  1.0065e-01],
        [ 2.4614e-01, -1.5699e-01, -2.3758e-01,  2.0623e-01, -2.0689e-01,
          2.9155e-01, -2.3517e-01,  1.6350e-01, -1.9673e-01, -6.6637e-01,
          5.8644e-01, -1.0473e-01, -1.7123e-01,  2.0354e-01, -6.5685e-03,
         -1.0549e-02, -8.1631e-02, -4.4509e-02,  1.6375e-01,  3.3834e-01],
        [ 2.5900e-01, -1.9590e-01, -1.8908e-02,  2.3223e-01, -1.9350e-01,
          4.3111e-01, -3.5888e-01,  1.5194e-01, -3.1214e-01, -6.2082e-01,
          9.3786e-01, -2.0748e-01, -1.7256e-01,  1.8636e-01, -1.8664e-01,
          2.7506e-02, -4.3032e-01, -6.8674e-02, -1.3081e-01,  5.2062e-01],
        [ 3.2412e-01, -3.5662e-02, -1.1445e-01,  1.2509e-01, -1.3449e-01,
          3.8028e-01, -2.6396e-02,  1.5592e-01, -3.7772e-01, -7.1327e-01,
          5.6802e-01, -3.1896e-01, -1.3078e-01,  1.6140e-01, -1.5517e-01,
          8.4159e-02, -5.0390e-02,  1.0843e-01, -1.7956e-01,  1.8594e-01],
        [-1.1480e-02, -3.0892e-01, -1.8073e-01,  1.9376e-01, -1.0964e-01,
          3.9109e-01, -4.5365e-01,  7.6031e-02, -2.7786e-01, -6.2149e-01,
          5.9212e-01,  4.7072e-02, -1.9695e-01,  6.3869e-02, -1.5271e-01,
          4.3038e-02, -7.0556e-02, -1.8535e-01,  6.0605e-03,  4.0809e-01],
        [ 7.1675e-02, -1.6989e-01, -1.3105e-01,  2.3434e-03, -1.0263e-01,
          4.7131e-01, -3.1614e-01,  3.2934e-02, -7.2475e-01, -7.7596e-01,
          9.8244e-01, -1.3397e-01, -2.1935e-01,  1.6064e-01, -1.7019e-01,
         -1.8191e-01, -4.0596e-02, -1.0912e-02, -3.3119e-01,  2.1468e-01],
        [ 1.7805e-01, -2.3648e-01,  1.2894e-01, -5.0974e-02,  1.0947e-02,
          3.8730e-01, -2.2170e-01,  3.7225e-01, -1.7139e-01, -5.1383e-01,
          5.3455e-01, -3.3462e-01, -1.5609e-01, -6.2295e-02, -1.5801e-03,
         -1.0878e-01, -1.0464e-01,  9.4912e-02, -1.5334e-02,  1.5421e-01],
        [ 1.8037e-01, -1.7893e-01, -2.4843e-01,  2.0525e-01, -1.1744e-01,
          3.8331e-01, -4.1080e-01,  2.0826e-01, -2.6039e-01, -3.2751e-01,
          4.2461e-01, -1.5350e-01, -2.2922e-01,  4.3687e-01, -8.8998e-02,
         -1.6762e-02, -1.6683e-01, -4.2039e-01, -1.7216e-01,  3.4636e-01],
        [ 7.0812e-02, -1.9962e-01, -7.0621e-02,  1.1541e-01, -5.1219e-02,
          3.3298e-01, -5.1188e-02,  2.5092e-01, -2.9964e-01, -5.2534e-01,
          5.6074e-01, -1.2552e-02, -2.7472e-01,  3.4297e-01, -5.2263e-02,
         -6.5564e-02,  8.6026e-02, -2.7250e-02, -1.2742e-02,  1.8805e-01],
        [ 1.6922e-01, -2.5991e-01,  1.5068e-01,  2.0756e-01,  7.5207e-02,
          1.7233e-01, -1.3357e-01,  1.4700e-01, -1.3626e-01, -6.9644e-01,
          7.0974e-01,  8.9555e-02, -3.4275e-01,  7.4008e-02, -6.6943e-02,
          5.3870e-03, -1.1319e-01, -2.6689e-01,  2.9585e-04,  1.3378e-01],
        [ 1.8907e-01, -3.1958e-01, -1.4793e-01,  2.1275e-01, -2.0657e-01,
          3.3795e-01, -2.9518e-01,  2.2178e-01, -4.1057e-01, -5.9257e-01,
          6.1340e-01, -2.7756e-02, -1.2982e-01,  2.2659e-01,  5.6751e-02,
          1.1057e-01, -1.7389e-01, -8.5971e-02, -5.1436e-02,  2.5102e-01],
        [ 3.5352e-01, -1.2115e-01,  1.6877e-01,  3.9919e-02, -1.8201e-01,
          3.7389e-01, -1.8828e-01,  1.4686e-01, -3.9400e-01, -8.7122e-01,
          7.5812e-01, -4.0709e-01, -1.7550e-01,  5.9655e-02, -1.5914e-01,
          8.7335e-02, -8.9806e-02,  6.5380e-02, -2.8616e-02,  2.6011e-01]],
       grad_fn=<AddmmBackward0>)
tensor([[0.1093, 0.3223, 0.0377, 0.2604, 0.1093, 0.1610],
        [0.0892, 0.0821, 0.0330, 0.0153, 0.6982, 0.0821],
        [0.0358, 0.1599, 0.4032, 0.1599, 0.0814, 0.1599],
        [0.2392, 0.2492, 0.1182, 0.1881, 0.0365, 0.1687],
        [0.1095, 0.0195, 0.1961, 0.0220, 0.0888, 0.5640],
        [0.0803, 0.0462, 0.2316, 0.0842, 0.2316, 0.3261],
        [0.1611, 0.4197, 0.1208, 0.0754, 0.1611, 0.0619],
        [0.0800, 0.2515, 0.2515, 0.2515, 0.0796, 0.0858],
        [0.2201, 0.2201, 0.0444, 0.2201, 0.0536, 0.2416],
        [0.3266, 0.1078, 0.0192, 0.2105, 0.2760, 0.0601],
        [0.4771, 0.2533, 0.0674, 0.0674, 0.0674, 0.0674],
        [0.0547, 0.0274, 0.7109, 0.0228, 0.1153, 0.0689],
        [0.1203, 0.1950, 0.1611, 0.1200, 0.0324, 0.3712],
        [0.0197, 0.5218, 0.0442, 0.2695, 0.0392, 0.1055],
        [0.3010, 0.4267, 0.0558, 0.1329, 0.0253, 0.0584],
        [0.2678, 0.1344, 0.2678, 0.1836, 0.0836, 0.0628]],
       grad_fn=<SoftmaxBackward0>)
None
None
tensor([[0.1093, 0.3223, 0.0377, 0.2604, 0.1093, 0.1610],
        [0.0892, 0.0821, 0.0330, 0.0153, 0.6982, 0.0821],
        [0.0358, 0.1599, 0.4032, 0.1599, 0.0814, 0.1599],
        [0.2392, 0.2492, 0.1182, 0.1881, 0.0365, 0.1687],
        [0.1095, 0.0195, 0.1961, 0.0220, 0.0888, 0.5640],
        [0.0803, 0.0462, 0.2316, 0.0842, 0.2316, 0.3261],
        [0.1611, 0.4197, 0.1208, 0.0754, 0.1611, 0.0619],
        [0.0800, 0.2515, 0.2515, 0.2515, 0.0796, 0.0858],
        [0.2201, 0.2201, 0.0444, 0.2201, 0.0536, 0.2416],
        [0.3266, 0.1078, 0.0192, 0.2105, 0.2760, 0.0601],
        [0.4771, 0.2533, 0.0674, 0.0674, 0.0674, 0.0674],
        [0.0547, 0.0274, 0.7109, 0.0228, 0.1153, 0.0689],
        [0.1203, 0.1950, 0.1611, 0.1200, 0.0324, 0.3712],
        [0.0197, 0.5218, 0.0442, 0.2695, 0.0392, 0.1055],
        [0.3010, 0.4267, 0.0558, 0.1329, 0.0253, 0.0584],
        [0.2678, 0.1344, 0.2678, 0.1836, 0.0836, 0.0628]],
       grad_fn=<SoftmaxBackward0>)
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "C:\Tue\Master\Jaar_2\graduation\code\own_approach\src\experiments\train_runner.py", line 209, in <module>
    run_training(parse_config_file(args.CONFIG_FP))
  File "C:\Tue\Master\Jaar_2\graduation\code\own_approach\src\experiments\train_runner.py", line 196, in run_training
    training.train(
  File "C:\Tue\Master\Jaar_2\graduation\code\own_approach\src\experiments\train.py", line 544, in train
    if not self._train_vae(train_loader, device, epoch):
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Tue\Master\Jaar_2\graduation\code\own_approach\src\experiments\train.py", line 221, in _train_vae
    pass_result = self._forward_pass(amp, phase, bvp, info["gesture"],
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Tue\Master\Jaar_2\graduation\code\own_approach\src\experiments\train.py", line 188, in _forward_pass
    loss_dict = self.loss_func(
                ^^^^^^^^^^^^^^^
  File "C:\Users\xande\anaconda3\Lib\site-packages\torch\nn\modules\module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\xande\anaconda3\Lib\site-packages\torch\nn\modules\module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Tue\Master\Jaar_2\graduation\code\own_approach\src\loss\multi_joint_loss.py", line 35, in forward
    null_domain_loss = self.ce(null_domain_pred, domain_label)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\xande\anaconda3\Lib\site-packages\torch\nn\modules\module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\xande\anaconda3\Lib\site-packages\torch\nn\modules\module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\xande\anaconda3\Lib\site-packages\torch\nn\modules\loss.py", line 1295, in forward
    return F.cross_entropy(
           ^^^^^^^^^^^^^^^^
  File "C:\Users\xande\anaconda3\Lib\site-packages\torch\nn\functional.py", line 3494, in cross_entropy
    return torch._C._nn.cross_entropy_loss(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: cross_entropy_loss(): argument 'target' (position 2) must be Tensor, not NoneType
