Running training on CPU
Loading dataset train
Found pregenerated data dir.
Loading complete. Took 0.01 s.
Loading dataset validation
Found pregenerated data dir.
Loading complete. Took 0.00 s.
Building models...
Completed model building. Took 24.66 s.
[2025-10-19 11:15:37 E001 S0000000] Preparation complete. Starting training...
[2025-10-19 11:16:05 E001 S0000000] Training model...
[2025-10-19 11:16:08 E001 S0000000] Started epoch 1, epoch: 0, batch: 0, train_loss: 1.83, train_domain_loss: 3.23, train_null_loss: 1.83, train_embed_loss: nan, train_loss_diff: nan
[2025-10-19 11:16:11 E001 S0000032] Started epoch 1, epoch: 0, batch: 1, train_loss: 1.77, train_domain_loss: 3.23, train_null_loss: 1.77, train_embed_loss: nan, train_loss_diff: nan
[2025-10-19 11:16:13 E001 S0000064] Started epoch 1, epoch: 0, batch: 2, train_loss: 1.77, train_domain_loss: 3.23, train_null_loss: 1.77, train_embed_loss: nan, train_loss_diff: nan
[2025-10-19 11:16:16 E001 S0000096] Started epoch 1, epoch: 0, batch: 3, train_loss: 1.83, train_domain_loss: 3.24, train_null_loss: 1.83, train_embed_loss: nan, train_loss_diff: nan
[2025-10-19 11:16:19 E001 S0000128] Started epoch 1, epoch: 0, batch: 4, train_loss: 1.79, train_domain_loss: 3.22, train_null_loss: 1.79, train_embed_loss: nan, train_loss_diff: nan
[2025-10-19 11:16:22 E001 S0000160] Started epoch 1, epoch: 0, batch: 5, train_loss: 1.77, train_domain_loss: 3.22, train_null_loss: 1.77, train_embed_loss: nan, train_loss_diff: nan
[2025-10-19 11:16:25 E001 S0000192] Started epoch 1, epoch: 0, batch: 6, train_loss: 1.75, train_domain_loss: 3.22, train_null_loss: 1.75, train_embed_loss: nan, train_loss_diff: nan
[2025-10-19 11:16:28 E001 S0000224] Started epoch 1, epoch: 0, batch: 7, train_loss: 1.74, train_domain_loss: 3.23, train_null_loss: 1.74, train_embed_loss: nan, train_loss_diff: nan
[2025-10-19 11:16:32 E001 S0000256] Started epoch 1, epoch: 0, batch: 8, train_loss: 1.83, train_domain_loss: 3.22, train_null_loss: 1.83, train_embed_loss: nan, train_loss_diff: nan
[2025-10-19 11:16:35 E001 S0000288] Started epoch 1, epoch: 0, batch: 9, train_loss: 1.83, train_domain_loss: 3.23, train_null_loss: 1.83, train_embed_loss: nan, train_loss_diff: nan
[2025-10-19 11:16:38 E001 S0000320] Started epoch 1, epoch: 0, batch: 10, train_loss: 1.67, train_domain_loss: 3.22, train_null_loss: 1.67, train_embed_loss: nan, train_loss_diff: nan
[2025-10-19 11:16:41 E001 S0000352] Started epoch 1, epoch: 0, batch: 11, train_loss: 1.68, train_domain_loss: 3.23, train_null_loss: 1.68, train_embed_loss: nan, train_loss_diff: nan
[2025-10-19 11:16:46 E001 S0000384] Started epoch 1, epoch: 0, batch: 12, train_loss: 1.77, train_domain_loss: 3.23, train_null_loss: 1.77, train_embed_loss: nan, train_loss_diff: nan
[2025-10-19 11:16:49 E001 S0000416] Started epoch 1, epoch: 0, batch: 13, train_loss: 1.72, train_domain_loss: 3.21, train_null_loss: 1.72, train_embed_loss: nan, train_loss_diff: nan
[2025-10-19 11:16:52 E001 S0000448] Started epoch 1, epoch: 0, batch: 14, train_loss: 1.81, train_domain_loss: 3.22, train_null_loss: 1.81, train_embed_loss: nan, train_loss_diff: nan
[2025-10-19 11:16:56 E001 S0000480] Started epoch 1, epoch: 0, batch: 15, train_loss: 1.69, train_domain_loss: 3.22, train_null_loss: 1.69, train_embed_loss: nan, train_loss_diff: nan
[2025-10-19 11:17:00 E001 S0000512] Started epoch 1, epoch: 0, batch: 16, train_loss: 1.74, train_domain_loss: 3.21, train_null_loss: 1.74, train_embed_loss: nan, train_loss_diff: nan
[2025-10-19 11:17:03 E001 S0000544] Started epoch 1, epoch: 0, batch: 17, train_loss: 1.67, train_domain_loss: 3.22, train_null_loss: 1.67, train_embed_loss: nan, train_loss_diff: nan
[2025-10-19 11:17:03 E001 S0000576] Running validation...
[2025-10-19 11:17:05 E001 S0000576] Started epoch 1, valid_loss: 5.08, loss_diff: 0.0, epoch: 0, batch: 0
[2025-10-19 11:17:07 E001 S0000608] Started epoch 1, valid_loss: 4.64, loss_diff: 0.0, epoch: 0, batch: 1
[2025-10-19 11:17:10 E001 S0000640] Started epoch 1, valid_loss: 4.93, loss_diff: 0.0, epoch: 0, batch: 2
[2025-10-19 11:17:11 E001 S0000672] Training model...
[2025-10-19 11:17:14 E002 S0000672] Started epoch 2, epoch: 1, batch: 0, train_loss: 1.67, train_domain_loss: 3.21, train_null_loss: 1.67, train_embed_loss: nan, train_loss_diff: nan
[2025-10-19 11:17:17 E002 S0000704] Started epoch 2, epoch: 1, batch: 1, train_loss: 1.63, train_domain_loss: 3.22, train_null_loss: 1.63, train_embed_loss: nan, train_loss_diff: nan
[2025-10-19 11:17:20 E002 S0000736] Started epoch 2, epoch: 1, batch: 2, train_loss: 1.7, train_domain_loss: 3.22, train_null_loss: 1.7, train_embed_loss: nan, train_loss_diff: nan
[2025-10-19 11:17:23 E002 S0000768] Started epoch 2, epoch: 1, batch: 3, train_loss: 1.75, train_domain_loss: 3.21, train_null_loss: 1.75, train_embed_loss: nan, train_loss_diff: nan
[2025-10-19 11:17:26 E002 S0000800] Started epoch 2, epoch: 1, batch: 4, train_loss: 1.77, train_domain_loss: 3.21, train_null_loss: 1.77, train_embed_loss: nan, train_loss_diff: nan
[2025-10-19 11:17:29 E002 S0000832] Started epoch 2, epoch: 1, batch: 5, train_loss: 1.75, train_domain_loss: 3.23, train_null_loss: 1.75, train_embed_loss: nan, train_loss_diff: nan
[2025-10-19 11:17:32 E002 S0000864] Started epoch 2, epoch: 1, batch: 6, train_loss: 1.67, train_domain_loss: 3.22, train_null_loss: 1.67, train_embed_loss: nan, train_loss_diff: nan
[2025-10-19 11:17:35 E002 S0000896] Started epoch 2, epoch: 1, batch: 7, train_loss: 1.67, train_domain_loss: 3.21, train_null_loss: 1.67, train_embed_loss: nan, train_loss_diff: nan
[2025-10-19 11:17:39 E002 S0000928] Started epoch 2, epoch: 1, batch: 8, train_loss: 1.69, train_domain_loss: 3.23, train_null_loss: 1.69, train_embed_loss: nan, train_loss_diff: nan
[2025-10-19 11:17:42 E002 S0000960] Started epoch 2, epoch: 1, batch: 9, train_loss: 1.7, train_domain_loss: 3.22, train_null_loss: 1.7, train_embed_loss: nan, train_loss_diff: nan
[2025-10-19 11:17:45 E002 S0000992] Started epoch 2, epoch: 1, batch: 10, train_loss: 1.69, train_domain_loss: 3.21, train_null_loss: 1.69, train_embed_loss: nan, train_loss_diff: nan
[2025-10-19 11:17:48 E002 S0001024] Started epoch 2, epoch: 1, batch: 11, train_loss: 1.6, train_domain_loss: 3.22, train_null_loss: 1.6, train_embed_loss: nan, train_loss_diff: nan
[2025-10-19 11:17:51 E002 S0001056] Started epoch 2, epoch: 1, batch: 12, train_loss: 1.76, train_domain_loss: 3.21, train_null_loss: 1.76, train_embed_loss: nan, train_loss_diff: nan
[2025-10-19 11:17:54 E002 S0001088] Started epoch 2, epoch: 1, batch: 13, train_loss: 1.75, train_domain_loss: 3.22, train_null_loss: 1.75, train_embed_loss: nan, train_loss_diff: nan
[2025-10-19 11:17:57 E002 S0001120] Started epoch 2, epoch: 1, batch: 14, train_loss: 1.69, train_domain_loss: 3.22, train_null_loss: 1.69, train_embed_loss: nan, train_loss_diff: nan
[2025-10-19 11:18:00 E002 S0001152] Started epoch 2, epoch: 1, batch: 15, train_loss: 1.73, train_domain_loss: 3.21, train_null_loss: 1.73, train_embed_loss: nan, train_loss_diff: nan
[2025-10-19 11:18:03 E002 S0001184] Started epoch 2, epoch: 1, batch: 16, train_loss: 1.72, train_domain_loss: 3.21, train_null_loss: 1.72, train_embed_loss: nan, train_loss_diff: nan
[2025-10-19 11:18:06 E002 S0001216] Started epoch 2, epoch: 1, batch: 17, train_loss: 1.74, train_domain_loss: 3.22, train_null_loss: 1.74, train_embed_loss: nan, train_loss_diff: nan
[2025-10-19 11:18:06 E002 S0001248] Running validation...
[2025-10-19 11:18:09 E002 S0001248] Started epoch 2, valid_loss: 4.92, loss_diff: 0.0, epoch: 1, batch: 0
[2025-10-19 11:18:11 E002 S0001280] Started epoch 2, valid_loss: 4.6, loss_diff: 0.0, epoch: 1, batch: 1
[2025-10-19 11:18:13 E002 S0001312] Started epoch 2, valid_loss: 4.92, loss_diff: 0.0, epoch: 1, batch: 2
[2025-10-19 11:18:13 E002 S0001344] Training model...
[2025-10-19 11:18:16 E003 S0001344] Started epoch 3, epoch: 2, batch: 0, train_loss: 1.64, train_domain_loss: 3.22, train_null_loss: 1.64, train_embed_loss: nan, train_loss_diff: nan
[2025-10-19 11:18:19 E003 S0001376] Started epoch 3, epoch: 2, batch: 1, train_loss: 1.67, train_domain_loss: 3.21, train_null_loss: 1.67, train_embed_loss: nan, train_loss_diff: nan
[2025-10-19 11:18:23 E003 S0001408] Started epoch 3, epoch: 2, batch: 2, train_loss: 1.69, train_domain_loss: 3.22, train_null_loss: 1.69, train_embed_loss: nan, train_loss_diff: nan
[2025-10-19 11:18:26 E003 S0001440] Started epoch 3, epoch: 2, batch: 3, train_loss: 1.73, train_domain_loss: 3.21, train_null_loss: 1.73, train_embed_loss: nan, train_loss_diff: nan
[2025-10-19 11:18:29 E003 S0001472] Started epoch 3, epoch: 2, batch: 4, train_loss: 1.63, train_domain_loss: 3.22, train_null_loss: 1.63, train_embed_loss: nan, train_loss_diff: nan
[2025-10-19 11:18:32 E003 S0001504] Started epoch 3, epoch: 2, batch: 5, train_loss: 1.74, train_domain_loss: 3.23, train_null_loss: 1.74, train_embed_loss: nan, train_loss_diff: nan
[2025-10-19 11:18:35 E003 S0001536] Started epoch 3, epoch: 2, batch: 6, train_loss: 1.67, train_domain_loss: 3.2, train_null_loss: 1.67, train_embed_loss: nan, train_loss_diff: nan
[2025-10-19 11:18:37 E003 S0001568] Started epoch 3, epoch: 2, batch: 7, train_loss: 1.69, train_domain_loss: 3.22, train_null_loss: 1.69, train_embed_loss: nan, train_loss_diff: nan
[2025-10-19 11:18:40 E003 S0001600] Started epoch 3, epoch: 2, batch: 8, train_loss: 1.72, train_domain_loss: 3.2, train_null_loss: 1.72, train_embed_loss: nan, train_loss_diff: nan
[2025-10-19 11:18:43 E003 S0001632] Started epoch 3, epoch: 2, batch: 9, train_loss: 1.69, train_domain_loss: 3.2, train_null_loss: 1.69, train_embed_loss: nan, train_loss_diff: nan
[2025-10-19 11:18:46 E003 S0001664] Started epoch 3, epoch: 2, batch: 10, train_loss: 1.67, train_domain_loss: 3.18, train_null_loss: 1.67, train_embed_loss: nan, train_loss_diff: nan
[2025-10-19 11:18:48 E003 S0001696] Started epoch 3, epoch: 2, batch: 11, train_loss: 1.67, train_domain_loss: 3.2, train_null_loss: 1.67, train_embed_loss: nan, train_loss_diff: nan
[2025-10-19 11:18:51 E003 S0001728] Started epoch 3, epoch: 2, batch: 12, train_loss: 1.77, train_domain_loss: 3.2, train_null_loss: 1.77, train_embed_loss: nan, train_loss_diff: nan
[2025-10-19 11:18:54 E003 S0001760] Started epoch 3, epoch: 2, batch: 13, train_loss: 1.7, train_domain_loss: 3.2, train_null_loss: 1.7, train_embed_loss: nan, train_loss_diff: nan
[2025-10-19 11:18:57 E003 S0001792] Started epoch 3, epoch: 2, batch: 14, train_loss: 1.68, train_domain_loss: 3.2, train_null_loss: 1.68, train_embed_loss: nan, train_loss_diff: nan
[2025-10-19 11:18:59 E003 S0001824] Started epoch 3, epoch: 2, batch: 15, train_loss: 1.74, train_domain_loss: 3.19, train_null_loss: 1.74, train_embed_loss: nan, train_loss_diff: nan
[2025-10-19 11:19:02 E003 S0001856] Started epoch 3, epoch: 2, batch: 16, train_loss: 1.62, train_domain_loss: 3.21, train_null_loss: 1.62, train_embed_loss: nan, train_loss_diff: nan
[2025-10-19 11:19:05 E003 S0001888] Started epoch 3, epoch: 2, batch: 17, train_loss: 1.76, train_domain_loss: 3.22, train_null_loss: 1.76, train_embed_loss: nan, train_loss_diff: nan
[2025-10-19 11:19:05 E003 S0001920] Running validation...
[2025-10-19 11:19:07 E003 S0001920] Started epoch 3, valid_loss: 4.88, loss_diff: 0.0, epoch: 2, batch: 0
[2025-10-19 11:19:09 E003 S0001952] Started epoch 3, valid_loss: 4.56, loss_diff: 0.0, epoch: 2, batch: 1
[2025-10-19 11:19:11 E003 S0001984] Started epoch 3, valid_loss: 4.73, loss_diff: 0.0, epoch: 2, batch: 2
[2025-10-19 11:19:11 E003 S0002016] Training model...
[2025-10-19 11:19:14 E004 S0002016] Started epoch 4, epoch: 3, batch: 0, train_loss: 1.68, train_domain_loss: 3.15, train_null_loss: 1.68, train_embed_loss: nan, train_loss_diff: nan
[2025-10-19 11:19:16 E004 S0002048] Started epoch 4, epoch: 3, batch: 1, train_loss: 1.67, train_domain_loss: 3.19, train_null_loss: 1.67, train_embed_loss: nan, train_loss_diff: nan
[2025-10-19 11:19:19 E004 S0002080] Started epoch 4, epoch: 3, batch: 2, train_loss: 1.56, train_domain_loss: 3.21, train_null_loss: 1.56, train_embed_loss: nan, train_loss_diff: nan
[2025-10-19 11:19:22 E004 S0002112] Started epoch 4, epoch: 3, batch: 3, train_loss: 1.76, train_domain_loss: 3.21, train_null_loss: 1.76, train_embed_loss: nan, train_loss_diff: nan
[2025-10-19 11:19:24 E004 S0002144] Started epoch 4, epoch: 3, batch: 4, train_loss: 1.75, train_domain_loss: 3.18, train_null_loss: 1.75, train_embed_loss: nan, train_loss_diff: nan
[2025-10-19 11:19:27 E004 S0002176] Started epoch 4, epoch: 3, batch: 5, train_loss: 1.69, train_domain_loss: 3.16, train_null_loss: 1.69, train_embed_loss: nan, train_loss_diff: nan
[2025-10-19 11:19:30 E004 S0002208] Started epoch 4, epoch: 3, batch: 6, train_loss: 1.63, train_domain_loss: 3.16, train_null_loss: 1.63, train_embed_loss: nan, train_loss_diff: nan
[2025-10-19 11:19:32 E004 S0002240] Started epoch 4, epoch: 3, batch: 7, train_loss: 1.67, train_domain_loss: 3.19, train_null_loss: 1.67, train_embed_loss: nan, train_loss_diff: nan
[2025-10-19 11:19:35 E004 S0002272] Started epoch 4, epoch: 3, batch: 8, train_loss: 1.73, train_domain_loss: 3.22, train_null_loss: 1.73, train_embed_loss: nan, train_loss_diff: nan
[2025-10-19 11:19:38 E004 S0002304] Started epoch 4, epoch: 3, batch: 9, train_loss: 1.66, train_domain_loss: 3.22, train_null_loss: 1.66, train_embed_loss: nan, train_loss_diff: nan
[2025-10-19 11:19:40 E004 S0002336] Started epoch 4, epoch: 3, batch: 10, train_loss: 1.73, train_domain_loss: 3.17, train_null_loss: 1.73, train_embed_loss: nan, train_loss_diff: nan
[2025-10-19 11:19:43 E004 S0002368] Started epoch 4, epoch: 3, batch: 11, train_loss: 1.68, train_domain_loss: 3.18, train_null_loss: 1.68, train_embed_loss: nan, train_loss_diff: nan
[2025-10-19 11:19:46 E004 S0002400] Started epoch 4, epoch: 3, batch: 12, train_loss: 1.68, train_domain_loss: 3.17, train_null_loss: 1.68, train_embed_loss: nan, train_loss_diff: nan
[2025-10-19 11:19:49 E004 S0002432] Started epoch 4, epoch: 3, batch: 13, train_loss: 1.75, train_domain_loss: 3.18, train_null_loss: 1.75, train_embed_loss: nan, train_loss_diff: nan
[2025-10-19 11:19:51 E004 S0002464] Started epoch 4, epoch: 3, batch: 14, train_loss: 1.65, train_domain_loss: 3.16, train_null_loss: 1.65, train_embed_loss: nan, train_loss_diff: nan
[2025-10-19 11:19:54 E004 S0002496] Started epoch 4, epoch: 3, batch: 15, train_loss: 1.7, train_domain_loss: 3.24, train_null_loss: 1.7, train_embed_loss: nan, train_loss_diff: nan
[2025-10-19 11:19:57 E004 S0002528] Started epoch 4, epoch: 3, batch: 16, train_loss: 1.63, train_domain_loss: 3.19, train_null_loss: 1.63, train_embed_loss: nan, train_loss_diff: nan
[2025-10-19 11:20:00 E004 S0002560] Started epoch 4, epoch: 3, batch: 17, train_loss: 1.68, train_domain_loss: 3.05, train_null_loss: 1.68, train_embed_loss: nan, train_loss_diff: nan
[2025-10-19 11:20:00 E004 S0002592] Running validation...
[2025-10-19 11:20:02 E004 S0002592] Started epoch 4, valid_loss: 4.92, loss_diff: 0.0, epoch: 3, batch: 0
[2025-10-19 11:20:04 E004 S0002624] Started epoch 4, valid_loss: 4.77, loss_diff: 0.0, epoch: 3, batch: 1
[2025-10-19 11:20:07 E004 S0002656] Started epoch 4, valid_loss: 4.6, loss_diff: 0.0, epoch: 3, batch: 2
[2025-10-19 11:20:07 E004 S0002688] Training model...
[2025-10-19 11:20:10 E005 S0002688] Started epoch 5, epoch: 4, batch: 0, train_loss: 1.72, train_domain_loss: 3.24, train_null_loss: 1.72, train_embed_loss: nan, train_loss_diff: nan
[2025-10-19 11:20:14 E005 S0002720] Started epoch 5, epoch: 4, batch: 1, train_loss: 1.66, train_domain_loss: 3.07, train_null_loss: 1.66, train_embed_loss: nan, train_loss_diff: nan
[2025-10-19 11:20:18 E005 S0002752] Started epoch 5, epoch: 4, batch: 2, train_loss: 1.64, train_domain_loss: 3.15, train_null_loss: 1.64, train_embed_loss: nan, train_loss_diff: nan
[2025-10-19 11:20:21 E005 S0002784] Started epoch 5, epoch: 4, batch: 3, train_loss: 1.69, train_domain_loss: 3.12, train_null_loss: 1.69, train_embed_loss: nan, train_loss_diff: nan
[2025-10-19 11:20:25 E005 S0002816] Started epoch 5, epoch: 4, batch: 4, train_loss: 1.63, train_domain_loss: 3.21, train_null_loss: 1.63, train_embed_loss: nan, train_loss_diff: nan
[2025-10-19 11:20:28 E005 S0002848] Started epoch 5, epoch: 4, batch: 5, train_loss: 1.7, train_domain_loss: 3.14, train_null_loss: 1.7, train_embed_loss: nan, train_loss_diff: nan
[2025-10-19 11:20:31 E005 S0002880] Started epoch 5, epoch: 4, batch: 6, train_loss: 1.67, train_domain_loss: 3.2, train_null_loss: 1.67, train_embed_loss: nan, train_loss_diff: nan
[2025-10-19 11:20:35 E005 S0002912] Started epoch 5, epoch: 4, batch: 7, train_loss: 1.69, train_domain_loss: 3.09, train_null_loss: 1.69, train_embed_loss: nan, train_loss_diff: nan
[2025-10-19 11:20:38 E005 S0002944] Started epoch 5, epoch: 4, batch: 8, train_loss: 1.65, train_domain_loss: 3.2, train_null_loss: 1.65, train_embed_loss: nan, train_loss_diff: nan
[2025-10-19 11:20:41 E005 S0002976] Started epoch 5, epoch: 4, batch: 9, train_loss: 1.67, train_domain_loss: 3.16, train_null_loss: 1.67, train_embed_loss: nan, train_loss_diff: nan
[2025-10-19 11:20:45 E005 S0003008] Started epoch 5, epoch: 4, batch: 10, train_loss: 1.64, train_domain_loss: 3.07, train_null_loss: 1.64, train_embed_loss: nan, train_loss_diff: nan
[2025-10-19 11:20:48 E005 S0003040] Started epoch 5, epoch: 4, batch: 11, train_loss: 1.61, train_domain_loss: 3.12, train_null_loss: 1.61, train_embed_loss: nan, train_loss_diff: nan
[2025-10-19 11:20:51 E005 S0003072] Started epoch 5, epoch: 4, batch: 12, train_loss: 1.59, train_domain_loss: 3.09, train_null_loss: 1.59, train_embed_loss: nan, train_loss_diff: nan
[2025-10-19 11:20:55 E005 S0003104] Started epoch 5, epoch: 4, batch: 13, train_loss: 1.71, train_domain_loss: 3.18, train_null_loss: 1.71, train_embed_loss: nan, train_loss_diff: nan
[2025-10-19 11:20:58 E005 S0003136] Started epoch 5, epoch: 4, batch: 14, train_loss: 1.64, train_domain_loss: 3.08, train_null_loss: 1.64, train_embed_loss: nan, train_loss_diff: nan
[2025-10-19 11:21:01 E005 S0003168] Started epoch 5, epoch: 4, batch: 15, train_loss: 1.78, train_domain_loss: 3.24, train_null_loss: 1.78, train_embed_loss: nan, train_loss_diff: nan
[2025-10-19 11:21:04 E005 S0003200] Started epoch 5, epoch: 4, batch: 16, train_loss: 1.68, train_domain_loss: 3.1, train_null_loss: 1.68, train_embed_loss: nan, train_loss_diff: nan
[2025-10-19 11:21:07 E005 S0003232] Started epoch 5, epoch: 4, batch: 17, train_loss: 1.72, train_domain_loss: 3.17, train_null_loss: 1.72, train_embed_loss: nan, train_loss_diff: nan
[2025-10-19 11:21:07 E005 S0003264] Running validation...
[2025-10-19 11:21:10 E005 S0003264] Started epoch 5, valid_loss: 5.0, loss_diff: 0.0, epoch: 4, batch: 0
[2025-10-19 11:21:12 E005 S0003296] Started epoch 5, valid_loss: 5.0, loss_diff: 0.0, epoch: 4, batch: 1
[2025-10-19 11:21:14 E005 S0003328] Started epoch 5, valid_loss: 4.57, loss_diff: 0.0, epoch: 4, batch: 2
[2025-10-19 11:21:15 E005 S0003360] Training embedding agent starting this epoch...
[2025-10-19 11:21:15 E005 S0003360] Training agent for 1200 steps...
[2025-10-19 11:32:50 E005 S0003360] Training model...
[2025-10-19 11:32:53 E006 S0003360] Started epoch 6, epoch: 5, batch: 0, train_loss: 1.69, train_domain_loss: 3.13, train_null_loss: 1.66, train_embed_loss: 1.72, train_loss_diff: 0.06
[2025-10-19 11:32:57 E006 S0003392] Started epoch 6, epoch: 5, batch: 1, train_loss: 1.65, train_domain_loss: 3.07, train_null_loss: 1.63, train_embed_loss: 1.68, train_loss_diff: 0.05
[2025-10-19 11:33:00 E006 S0003424] Started epoch 6, epoch: 5, batch: 2, train_loss: 1.63, train_domain_loss: 3.19, train_null_loss: 1.61, train_embed_loss: 1.66, train_loss_diff: 0.05
[2025-10-19 11:33:03 E006 S0003456] Started epoch 6, epoch: 5, batch: 3, train_loss: 1.64, train_domain_loss: 3.08, train_null_loss: 1.64, train_embed_loss: 1.64, train_loss_diff: -0.0
[2025-10-19 11:33:06 E006 S0003488] Started epoch 6, epoch: 5, batch: 4, train_loss: 1.64, train_domain_loss: 3.02, train_null_loss: 1.64, train_embed_loss: 1.65, train_loss_diff: 0.01
[2025-10-19 11:33:09 E006 S0003520] Started epoch 6, epoch: 5, batch: 5, train_loss: 1.67, train_domain_loss: 3.1, train_null_loss: 1.67, train_embed_loss: 1.66, train_loss_diff: -0.01
[2025-10-19 11:33:12 E006 S0003552] Started epoch 6, epoch: 5, batch: 6, train_loss: 1.66, train_domain_loss: 3.09, train_null_loss: 1.61, train_embed_loss: 1.7, train_loss_diff: 0.09
[2025-10-19 11:33:15 E006 S0003584] Started epoch 6, epoch: 5, batch: 7, train_loss: 1.59, train_domain_loss: 3.07, train_null_loss: 1.58, train_embed_loss: 1.61, train_loss_diff: 0.03
[2025-10-19 11:33:19 E006 S0003616] Started epoch 6, epoch: 5, batch: 8, train_loss: 1.67, train_domain_loss: 3.13, train_null_loss: 1.67, train_embed_loss: 1.68, train_loss_diff: 0.01
[2025-10-19 11:33:22 E006 S0003648] Started epoch 6, epoch: 5, batch: 9, train_loss: 1.67, train_domain_loss: 3.03, train_null_loss: 1.67, train_embed_loss: 1.67, train_loss_diff: 0.01
[2025-10-19 11:33:26 E006 S0003680] Started epoch 6, epoch: 5, batch: 10, train_loss: 1.64, train_domain_loss: 3.25, train_null_loss: 1.64, train_embed_loss: 1.64, train_loss_diff: 0.0
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "C:\Tue\Master\Jaar_2\graduation\code\own_approach\src\experiments\train_runner.py", line 235, in <module>
    best_loss = run_training(parse_config_file(args.CONFIG_FP))
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Tue\Master\Jaar_2\graduation\code\own_approach\src\experiments\train_runner.py", line 221, in run_training
    best_loss = training.train(
                ^^^^^^^^^^^^^^^
  File "C:\Tue\Master\Jaar_2\graduation\code\own_approach\src\experiments\train.py", line 594, in train
    if not self._train_backbone(train_loader, device, epoch):
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Tue\Master\Jaar_2\graduation\code\own_approach\src\experiments\train.py", line 232, in _train_backbone
    pass_result = self._forward_pass(
                  ^^^^^^^^^^^^^^^^^^^
  File "C:\Tue\Master\Jaar_2\graduation\code\own_approach\src\experiments\train.py", line 171, in _forward_pass
    z = self.encoder(amp, phase, bvp)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\xande\anaconda3\Lib\site-packages\torch\nn\modules\module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\xande\anaconda3\Lib\site-packages\torch\nn\modules\module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Tue\Master\Jaar_2\graduation\code\own_approach\src\backbone\BackBoneArchitecture.py", line 73, in forward
    z_amp = self.amp_backbone(amp)
            ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\xande\anaconda3\Lib\site-packages\torch\nn\modules\module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\xande\anaconda3\Lib\site-packages\torch\nn\modules\module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Tue\Master\Jaar_2\graduation\code\own_approach\src\backbone\CNN.py", line 50, in forward
    x = self.conv_layers(x)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\xande\anaconda3\Lib\site-packages\torch\nn\modules\module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\xande\anaconda3\Lib\site-packages\torch\nn\modules\module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\xande\anaconda3\Lib\site-packages\torch\nn\modules\container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "C:\Users\xande\anaconda3\Lib\site-packages\torch\nn\modules\module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\xande\anaconda3\Lib\site-packages\torch\nn\modules\module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\xande\anaconda3\Lib\site-packages\torch\nn\modules\conv.py", line 554, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\xande\anaconda3\Lib\site-packages\torch\nn\modules\conv.py", line 549, in _conv_forward
    return F.conv2d(
           ^^^^^^^^^
KeyboardInterrupt
