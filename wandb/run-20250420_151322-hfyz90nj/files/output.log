Running training on CPU
Loading dataset train
Found pregenerated data dir. Using pregenerated data.
Loading complete. Took 0.00 s.
Loading dataset validation
Found pregenerated data dir. Using pregenerated data.
Loading complete. Took 0.00 s.
Building models...
Completed model building. Took 0.04 s.
Epoch: 1 of 50 | Training loss: -.--:   0%|                                                                                          | 0/12000 [00:00<?, ?it/s]Traceback (most recent call last):
Preparation complete. Starting training...
Training model...
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "C:\Tue\Master\Jaar_2\graduation\code\own_approach\src\experiments\train_runner.py", line 209, in <module>
    run_training(parse_config_file(args.CONFIG_FP))
  File "C:\Tue\Master\Jaar_2\graduation\code\own_approach\src\experiments\train_runner.py", line 196, in run_training
    training.train(
  File "C:\Tue\Master\Jaar_2\graduation\code\own_approach\src\experiments\train.py", line 564, in train
    if not self._train_vae(train_loader, device, epoch):
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Tue\Master\Jaar_2\graduation\code\own_approach\src\experiments\train.py", line 219, in _train_vae
    pass_result = self._forward_pass(amp, phase, bvp, info["gesture"],
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Tue\Master\Jaar_2\graduation\code\own_approach\src\experiments\train.py", line 146, in _forward_pass
    z = self.encoder(amp, phase, bvp)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\xande\anaconda3\Lib\site-packages\torch\nn\modules\module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\xande\anaconda3\Lib\site-packages\torch\nn\modules\module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Tue\Master\Jaar_2\graduation\code\own_approach\src\backbone\BackBoneArchitecture.py", line 40, in forward
    z_amp = self.amp_backbone(amp)
            ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\xande\anaconda3\Lib\site-packages\torch\nn\modules\module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\xande\anaconda3\Lib\site-packages\torch\nn\modules\module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Tue\Master\Jaar_2\graduation\code\own_approach\src\backbone\ViT.py", line 71, in forward
    x = self.transformer(x)       # [B, N+1, base_channels]
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\xande\anaconda3\Lib\site-packages\torch\nn\modules\module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\xande\anaconda3\Lib\site-packages\torch\nn\modules\module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Tue\Master\Jaar_2\graduation\code\own_approach\src\backbone\ViT.py", line 34, in forward
    return self.transformer(x)  # [B, N+1, E]
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\xande\anaconda3\Lib\site-packages\torch\nn\modules\module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\xande\anaconda3\Lib\site-packages\torch\nn\modules\module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\xande\anaconda3\Lib\site-packages\torch\nn\modules\transformer.py", line 517, in forward
    output = mod(
             ^^^^
  File "C:\Users\xande\anaconda3\Lib\site-packages\torch\nn\modules\module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\xande\anaconda3\Lib\site-packages\torch\nn\modules\module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\xande\anaconda3\Lib\site-packages\torch\nn\modules\transformer.py", line 920, in forward
    + self._sa_block(x, src_mask, src_key_padding_mask, is_causal=is_causal)
      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\xande\anaconda3\Lib\site-packages\torch\nn\modules\transformer.py", line 934, in _sa_block
    x = self.self_attn(
        ^^^^^^^^^^^^^^^
  File "C:\Users\xande\anaconda3\Lib\site-packages\torch\nn\modules\module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\xande\anaconda3\Lib\site-packages\torch\nn\modules\module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\xande\anaconda3\Lib\site-packages\torch\nn\modules\activation.py", line 1373, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\xande\anaconda3\Lib\site-packages\torch\nn\functional.py", line 6410, in multi_head_attention_forward
    attn_output = scaled_dot_product_attention(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: [enforce fail at alloc_cpu.cpp:115] data. DefaultCPUAllocator: not enough memory: you tried to allocate 6507971584 bytes.
