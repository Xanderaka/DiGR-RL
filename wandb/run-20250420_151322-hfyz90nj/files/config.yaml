_wandb:
    value:
        cli_version: 0.19.8
        m: []
        python_version: 3.12.3
        t:
            "1":
                - 1
                - 5
                - 41
                - 53
                - 55
            "2":
                - 1
                - 5
                - 41
                - 53
                - 55
            "3":
                - 15
                - 16
                - 23
                - 55
            "4": 3.12.3
            "5": 0.19.8
            "8":
                - 3
                - 5
            "12": 0.19.8
            "13": windows-amd64
data:
    value:
        amp_pipeline: <src.signal_processing.pipeline.Pipeline object at 0x000001BEFDD03C80>
        bvp_agg: sum
        bvp_pipeline: 0
        data_dir: C:\Tue\Master\Jaar_2\graduation\code\own_approach\data
        dataset_type: single_user
        downsample_multiplier: 100
        phase_pipeline: <src.signal_processing.pipeline.Pipeline object at 0x000001BEFD798530>
        transformation: RecurrencePlotTransform()
debug:
    value:
        is_debug: false
        offline: false
        on_cpu: false
embed:
    value:
        actor_dropout: 0.3
        actor_num_layers: 3
        agent_type: ppo
        anneal_lr: true
        clip_coef: 0.2
        clip_value_loss: true
        critic_dropout: 0.3
        critic_num_layers: 3
        embed_size: 33
        entropy_coef: 0
        epochs: 2
        gae_lambda: 0.95
        gamma: 0.99
        lr: 0.0001
        max_grad_norm: 0.5
        norm_advantage: true
        reward_function: maximize_difference
        start_epoch: 15
        target_kl: null
        value_func_coef: 0.5
        value_type: probability-measure
encoder:
    value:
        Backbone_type: ViT
        activation_fn: leaky
        dropout: 0.18
        initial_kernel_size: 7
        latent_dim: 60
        normalization: false
mt:
    value:
        decoder_activation_fn: leaky
        decoder_dropout: 0.26
        predictor_activation_fn: selu
        predictor_dropout: 0.28
        predictor_num_layers: 4
optim_loss:
    value:
        alpha: 8e-05
        beta: 0.5
        lr: 0.00022
        optimizer: adam
train:
    value:
        batch_size: 16
        checkpoint_dir: ..\..\checkpoints
        epochs: 50
        ui: tqdm
