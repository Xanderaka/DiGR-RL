Running training on CPU
Loading dataset train
Found pregenerated data dir.
Loading complete. Took 0.01 s.
Loading dataset validation
Found pregenerated data dir.
Loading complete. Took 0.01 s.
Building models...
Completed model building. Took 26.52 s.
Epoch: 1 of 100 | Training loss: 1.65:   1%|â–Œ                                                                                  | 480/72000 [01:04<1:31:07, 13.08it/s]Traceback (most recent call last):
Preparation complete. Starting training...
Training model...
{'epoch': 0, 'batch': 0, 'train_loss': 1.805, 'train_domain_loss': 3.222, 'train_null_loss': 1.805, 'train_embed_loss': nan, 'train_loss_diff': nan}
{'epoch': 0, 'batch': 1, 'train_loss': 1.748, 'train_domain_loss': 3.217, 'train_null_loss': 1.748, 'train_embed_loss': nan, 'train_loss_diff': nan}
{'epoch': 0, 'batch': 2, 'train_loss': 1.719, 'train_domain_loss': 3.218, 'train_null_loss': 1.719, 'train_embed_loss': nan, 'train_loss_diff': nan}
{'epoch': 0, 'batch': 3, 'train_loss': 1.722, 'train_domain_loss': 3.234, 'train_null_loss': 1.722, 'train_embed_loss': nan, 'train_loss_diff': nan}
{'epoch': 0, 'batch': 4, 'train_loss': 1.701, 'train_domain_loss': 3.22, 'train_null_loss': 1.701, 'train_embed_loss': nan, 'train_loss_diff': nan}
{'epoch': 0, 'batch': 5, 'train_loss': 1.673, 'train_domain_loss': 3.214, 'train_null_loss': 1.673, 'train_embed_loss': nan, 'train_loss_diff': nan}
{'epoch': 0, 'batch': 6, 'train_loss': 1.73, 'train_domain_loss': 3.214, 'train_null_loss': 1.73, 'train_embed_loss': nan, 'train_loss_diff': nan}
{'epoch': 0, 'batch': 7, 'train_loss': 1.702, 'train_domain_loss': 3.215, 'train_null_loss': 1.702, 'train_embed_loss': nan, 'train_loss_diff': nan}
{'epoch': 0, 'batch': 8, 'train_loss': 1.599, 'train_domain_loss': 3.225, 'train_null_loss': 1.599, 'train_embed_loss': nan, 'train_loss_diff': nan}
{'epoch': 0, 'batch': 9, 'train_loss': 1.73, 'train_domain_loss': 3.238, 'train_null_loss': 1.73, 'train_embed_loss': nan, 'train_loss_diff': nan}
{'epoch': 0, 'batch': 10, 'train_loss': 1.678, 'train_domain_loss': 3.231, 'train_null_loss': 1.678, 'train_embed_loss': nan, 'train_loss_diff': nan}
{'epoch': 0, 'batch': 11, 'train_loss': 1.637, 'train_domain_loss': 3.236, 'train_null_loss': 1.637, 'train_embed_loss': nan, 'train_loss_diff': nan}
{'epoch': 0, 'batch': 12, 'train_loss': 1.705, 'train_domain_loss': 3.208, 'train_null_loss': 1.705, 'train_embed_loss': nan, 'train_loss_diff': nan}
{'epoch': 0, 'batch': 13, 'train_loss': 1.71, 'train_domain_loss': 3.227, 'train_null_loss': 1.71, 'train_embed_loss': nan, 'train_loss_diff': nan}
{'epoch': 0, 'batch': 14, 'train_loss': 1.646, 'train_domain_loss': 3.21, 'train_null_loss': 1.646, 'train_embed_loss': nan, 'train_loss_diff': nan}
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "C:\Tue\Master\Jaar_2\graduation\code\own_approach\src\experiments\train_runner.py", line 220, in <module>
    best_loss = run_training(parse_config_file(args.CONFIG_FP))
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Tue\Master\Jaar_2\graduation\code\own_approach\src\experiments\train_runner.py", line 206, in run_training
    best_loss = training.train(
                ^^^^^^^^^^^^^^^
  File "C:\Tue\Master\Jaar_2\graduation\code\own_approach\src\experiments\train.py", line 568, in train
    if not self._train_backbone(train_loader, device, epoch):
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Tue\Master\Jaar_2\graduation\code\own_approach\src\experiments\train.py", line 225, in _train_backbone
    for batch_idx, (amp, phase, bvp, info) in enumerate(train_loader):
  File "C:\Users\xande\anaconda3\Lib\site-packages\torch\utils\data\dataloader.py", line 708, in __next__
    data = self._next_data()
           ^^^^^^^^^^^^^^^^^
  File "C:\Users\xande\anaconda3\Lib\site-packages\torch\utils\data\dataloader.py", line 764, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\xande\anaconda3\Lib\site-packages\torch\utils\data\_utils\fetch.py", line 52, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
            ~~~~~~~~~~~~^^^^^
  File "C:\Tue\Master\Jaar_2\graduation\code\own_approach\src\data_utils\widar_dataset.py", line 185, in __getitem__
    amp, phase = torch.tensor(data["x_amp"]), torch.tensor(data["x_phase"])
                              ~~~~^^^^^^^^^
  File "C:\Users\xande\anaconda3\Lib\site-packages\numpy\lib\npyio.py", line 256, in __getitem__
    return format.read_array(bytes,
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\xande\anaconda3\Lib\site-packages\numpy\lib\format.py", line 831, in read_array
    data = _read_bytes(fp, read_size, "array data")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\xande\anaconda3\Lib\site-packages\numpy\lib\format.py", line 966, in _read_bytes
    r = fp.read(size - len(data))
        ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\xande\anaconda3\Lib\zipfile\__init__.py", line 989, in read
    data = self._read1(n)
           ^^^^^^^^^^^^^^
  File "C:\Users\xande\anaconda3\Lib\zipfile\__init__.py", line 1065, in _read1
    data = self._decompressor.decompress(data, n)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
